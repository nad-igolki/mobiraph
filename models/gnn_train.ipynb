{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:56.985163Z",
     "start_time": "2024-12-24T02:18:55.167834Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.graphgym import train\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.data import DataLoader\n",
    "import os\n",
    "import pickle"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nad/miniconda3/envs/sna/lib/python3.9/site-packages/torch_geometric/graphgym/config.py:19: UserWarning: Could not define global config object. Please install 'yacs' via 'pip install yacs' in order to use GraphGym\n",
      "  warnings.warn(\"Could not define global config object. Please install \"\n",
      "/Users/nad/miniconda3/envs/sna/lib/python3.9/site-packages/torch_geometric/graphgym/imports.py:14: UserWarning: Please install 'pytorch_lightning' via  'pip install pytorch_lightning' in order to use GraphGym\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' via  \"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:56.998316Z",
     "start_time": "2024-12-24T02:18:56.996488Z"
    }
   },
   "cell_type": "code",
   "source": "os.chdir('..')",
   "id": "4ef6a39a262ec11b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Преобразование графа в нужный формат",
   "id": "ec96689276d4bc96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.033536Z",
     "start_time": "2024-12-24T02:18:57.031009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def nx_to_pyg_data(G, node_characteristics, label):\n",
    "   # Получаем числовые индексы для рёбер\n",
    "    edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Фичи для каждого узла\n",
    "    x = torch.tensor(node_characteristics)\n",
    "    y = torch.tensor([label])\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, y=y)"
   ],
   "id": "6e19031053f3f8c3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Графы для обучения",
   "id": "4fa7c1dcc54afe24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.040311Z",
     "start_time": "2024-12-24T02:18:57.038449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_components_all = {}\n",
    "small_components_families_all = {}\n",
    "largest_component_all = {}\n",
    "largest_component_families_all = {}"
   ],
   "id": "4664b7abc9e53e3d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.049827Z",
     "start_time": "2024-12-24T02:18:57.046745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция для загрузки данных из файла\n",
    "def load_data_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Процесс получения меток для маленьких компонент\n",
    "def process_small_components(name):\n",
    "    small_components_families_filename = os.path.join('data', f'small_components_families_{name}.pkl')\n",
    "    if os.path.exists(small_components_families_filename):\n",
    "        data = load_data_from_file(small_components_families_filename)\n",
    "        if data:\n",
    "            small_components_families_all[name] = data['families']\n",
    "            small_components_all[name] = data['components']\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Процесс получения кластеров и меток для большой компоненты\n",
    "def process_largest_component(name):\n",
    "    largest_component_filename = os.path.join('data', f'largest_component_clusters_{name}.pkl')\n",
    "    if os.path.exists(largest_component_filename):\n",
    "        data = load_data_from_file(largest_component_filename)\n",
    "        if data:\n",
    "            largest_component = data['clusters']\n",
    "            largest_component_families = data['families']\n",
    "            \n",
    "            largest_component_all[name] = largest_component\n",
    "            largest_component_families_all[name] = largest_component_families\n",
    "        return True\n",
    "    return False\n",
    "    "
   ],
   "id": "4cb1a5534c53fd80",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.056644Z",
     "start_time": "2024-12-24T02:18:57.053500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name = 'arab'\n",
    "if not process_small_components(name):\n",
    "    print(f\"File for {name} (small components families) not found.\")\n",
    "\n",
    "if not process_largest_component(name):\n",
    "    print(f\"File for {name} (largest component) not found.\")"
   ],
   "id": "a5546b9fd9d9ce6e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.067104Z",
     "start_time": "2024-12-24T02:18:57.060945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pickle_filename = os.path.join('data', f'X_y_characteristics.pkl')\n",
    "X = None\n",
    "y = None\n",
    "if os.path.exists(pickle_filename):\n",
    "    try:\n",
    "        with open(pickle_filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        X = data['X']\n",
    "        y = data['y']\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name}: {e}\")\n",
    "else:\n",
    "    print(f\"File for {name} not found.\")"
   ],
   "id": "7945bf27282f0e44",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.080120Z",
     "start_time": "2024-12-24T02:18:57.072649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "G = nx.Graph()\n",
    "    \n",
    "# Загрузка графа\n",
    "with open('data_arab/graph_collapse.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        node1, node2 = line.strip().split()\n",
    "        G.add_edge(node1, node2)"
   ],
   "id": "210a8e75ed03ef52",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.103167Z",
     "start_time": "2024-12-24T02:18:57.086003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "G_new = G.copy()\n",
    "vertex_map = {old_vertex: idx for idx, old_vertex in enumerate(G.nodes())}\n",
    "G_new.add_nodes_from(vertex_map.values())\n",
    "for u, v in G.edges():\n",
    "    G_new.add_edge(vertex_map[u], vertex_map[v])"
   ],
   "id": "681e616e648a02c2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.112523Z",
     "start_time": "2024-12-24T02:18:57.110673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "families_to_filter = ['LTR', 'Helitron', 'DNA/MuDR', 'LINE']\n",
    "families_dict = {type_str: idx for idx, type_str in enumerate(families_to_filter)}"
   ],
   "id": "ad31d419ee90158e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.171440Z",
     "start_time": "2024-12-24T02:18:57.119982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = []\n",
    "\n",
    "components = list(small_components_all[name]) + list(largest_component_all[name])\n",
    "families = list(small_components_families_all[name]) + list(largest_component_families_all[name])\n",
    "\n",
    "for i in range(len(components)):\n",
    "    if families[i] not in families_to_filter:\n",
    "        continue\n",
    "    component_nodes = components[i]\n",
    "    G_sub = G.subgraph(component_nodes)\n",
    "\n",
    "    G_sub_new = G_new.subgraph([vertex_map[x] for x in component_nodes])\n",
    "\n",
    "    target = [0] * len(families_to_filter)\n",
    "    target[families_dict[families[i]]] = 1\n",
    "\n",
    "    graph_embedding = nx_to_pyg_data(G_sub_new, X[i], target)\n",
    "    train_data.append(graph_embedding)"
   ],
   "id": "64c7a36d2e66472a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.181923Z",
     "start_time": "2024-12-24T02:18:57.180036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Создаем DataLoader для батчей\n",
    "loader = DataLoader(train_data, batch_size=16, shuffle=True)"
   ],
   "id": "3fa073e616ca1d43",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Обучение",
   "id": "62da401ecbc7bf8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:18:57.193696Z",
     "start_time": "2024-12-24T02:18:57.191010Z"
    }
   },
   "cell_type": "code",
   "source": "from models.gnn import GNN",
   "id": "34008fecf3951716",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = GNN(in_channels=103, hidden_channels=16, out_channels=4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Функция потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Тренировочный цикл\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, edge_index_batch, y_batch, _, _ in loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Обработка каждого графа в батче\n",
    "        batch_loss = 0\n",
    "        for x, edge_index, y in zip(x_batch, edge_index_batch, y_batch):\n",
    "            out = model(x, edge_index)\n",
    "            loss = criterion(out, y)\n",
    "            batch_loss += loss\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += batch_loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(loader)}\")"
   ],
   "id": "a4067f8809eec673",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
